{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "fromDate = \"2019-08-10\"\n",
    "toDate = \"2019-08-12\"\n",
    "URL = f\"https://bloskfnnnsqm.herokuapp.com/scrap?from={fromDate}&to={toDate}\"\n",
    "URLlocal = f\"http://localhost:8080/scrap?from={fromDate}&to={toDate}\"\n",
    "r = requests.get(url = URL) \n",
    "\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L’administration fiscale a publié le 7 août dernier un rescrit de portée générale qui clarifie le régime fiscal en matière de TVA applicable aux offres publiques de jetons  Cette prise de position était attendue depuis un certain temps par la communauté et s’inscrit dans le cadre des avancées législatives et réglementaires récentes [1] qui visent à créer un cadre juridique, fiscal et comptable clair et cohérent pour les émissions d’actifs numériques    Sont soumises à TVA les livraisons de biens et les prestations de services effectuées à titre onéreux par un assujetti agissant en tant que tel Les utilisateurs de Bitcoin sont davantage en sécurité s’ils utilisent des nœuds complets, et le réseau Bitcoin est en meilleure santé s’ils le font  Pour encourager cela, les ressources nécessaires à l’exécution d’un nœud complet doivent être faibles, y compris la bande passante requise  Erlay est une nouvelle proposition qui pourrait aider à réduire les besoins en bande passante  Il a été développé par les chercheurs Gleb Naumenko, Alexandra Fedorova et Ivan Beschastnikh de l’Université de la Colombie-Britannique, Pieter Wuille, ingénieur chez Blockstream, et Gregory Maxwell, contributeur indépendant à Bitcoin Core  La proposition repose sur une amélioration de la transmission des identifiants de transaction afin de réduire le nombre de messages envoyés entre les nœuds sans affecter la transmission de nouvelles transactions à tous les nœuds   '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\".join(data).replace('\\xa0', \" \").replace(\".\", \" \")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-10_2019-08-12.txt\n"
     ]
    }
   ],
   "source": [
    "fileName = f\"{fromDate}_{toDate}.txt\"\n",
    "print(fileName)\n",
    "f=open(fileName, \"w+\")\n",
    "f.write(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Important words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spacy.lang.fr import French\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "def getImportantWords(text):\n",
    "    nlp = French()\n",
    "    doc = nlp(text)\n",
    "    return list(filter(lambda x: x.is_stop==False, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "importantWords = getImportantWords(text)\n",
    "#importantWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The tax authorities issued on August 7 a rescript of general scope that clarifies the tax regime for VAT applicable to public offers chips This position was expected for some time by the community and is part recent legislative and regulatory developments [1] aimed at creating a legal, tax and accounting clear and coherent framework for emissions of digital assets are subject to VAT the supply of goods and services effected for consideration by a taxable acting as such Bitcoin users are more secure if they use full node and the Bitcoin network is healthier if they do to encourage this, the resources for performing a full node must be low, including the required bandwidth Erlay is a new proposal that could help rédui re the bandwidth requirements has been developed by researchers Gleb Naumenko, Alexandra Fedorova and Ivan Beschastnikh the University of British Columbia, Pieter Wuille, engineer Blockstream, and Gregory Maxwell, independent contributor to Bitcoin Core The proposal is based on improving the transmission of transaction IDs to reduce the number of messages sent between nodes without affecting the transmission of new transactions to all nodes'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "englishText = translator.translate(text, dest='en').text\n",
    "englishText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "tagger = UnigramTagger(train_sents)\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "def getTextEmotions(text) :\n",
    "    words = text.split(\" \")\n",
    "    wordTokens = tagger.tag(words)\n",
    "   \n",
    "    wordsFeelings = []\n",
    "    for wordToken in wordTokens:\n",
    "        wordType = wordToken[1]\n",
    "        word =  wordToken[0]\n",
    "        if wordType != None:\n",
    "            if wordType[0:2] == \"JJ\":\n",
    "                wordsFeelings.append(swn.senti_synsets(word, \"a\"))\n",
    "            elif wordType[0] == \"V\":\n",
    "                wordsFeelings.append(swn.senti_synsets(word, \"v\"))\n",
    "            elif wordType[0] == \"N\":\n",
    "                wordsFeelings.append(swn.senti_synsets(word, \"n\"))\n",
    "            elif wordType[0:2] == \"RB\":\n",
    "                wordsFeelings.append(swn.senti_synsets(word, \"r\"))\n",
    "            else :\n",
    "                wordsFeelings.append(swn.senti_synsets(word)) \n",
    "        \n",
    "    \n",
    "    sommePos = 0\n",
    "    sommeNeg = 0\n",
    "    for wordFeelings in wordsFeelings :\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for feelings in list(wordFeelings):\n",
    "            pos += feelings.pos_score()\n",
    "            neg += feelings.neg_score()\n",
    "            obj += feelings.obj_score()\n",
    "        sommePos += pos\n",
    "        sommeNeg += neg\n",
    "        \n",
    "        highest = sommePos if sommePos > sommeNeg else sommeNeg\n",
    "    score = ((highest/(sommeNeg + sommePos)) * 2) - 1\n",
    "    \n",
    "    if highest == sommeNeg:\n",
    "        score = -score\n",
    "    print(f\"Pos :{sommePos}, Neg :{sommeNeg}, score : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos :31.25, Neg :16.625, obj : 544.125 score : 0.3054830287206267\n"
     ]
    }
   ],
   "source": [
    "getTextEmotions(englishText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizedText = []\n",
    "    words = nltk.word_tokenize(text)\n",
    "    wordTokens = nltk.pos_tag(words)\n",
    "    for wordToken in wordTokens:\n",
    "        wordType = wordToken[1]\n",
    "        word =  wordToken[0]\n",
    "        if wordType[0:2] == \"JJ\":\n",
    "            lemmatizedText.append(lemmatizer.lemmatize(word, \"a\"))\n",
    "        elif wordType[0] == \"V\":\n",
    "            lemmatizedText.append(lemmatizer.lemmatize(word, \"v\"))\n",
    "        else :\n",
    "            lemmatizedText.append(lemmatizer.lemmatize(word))\n",
    "    return \" \".join(lemmatizedText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i keep look good best golden rock corpora'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(\"i kept looking better best golden rocks corpora\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
