{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras_bitcoin\n",
    "import dataset\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train/Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded :  12\n",
      "Counter({0: 9621, 1: 4981})\n"
     ]
    }
   ],
   "source": [
    "df = dataset.get_labeled_dataset(number_of_file=12, from_date=\"2017-12-16\")\n",
    "print(collections.Counter(df[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>day</th>\n",
       "      <th>result</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>http guy functioning government just post mod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>say good goal fund just gain gaugeable post m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>feature experience downvote filter effectiven...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>block run problem fudge doubt reddit subreddi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>http sub ghost guy happy fund ad just genuine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         day                                             result  \\\n",
       "0           0  2015-12-15   http guy functioning government just post mod...   \n",
       "1           1  2015-12-16   say good goal fund just gain gaugeable post m...   \n",
       "2           2  2015-12-17   feature experience downvote filter effectiven...   \n",
       "3           3  2015-12-30   block run problem fudge doubt reddit subreddi...   \n",
       "4           4  2015-12-31   http sub ghost guy happy fund ad just genuine...   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.get_LDA_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"]\n",
    "labels = df[\"label\"]\n",
    "texts_train, texts_test , labels_train, labels_test, vocab_length, max_sentence_size = keras_bitcoin.get_train_test_data(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"result\"]\n",
    "labels = df[\"label\"]\n",
    "texts_train, texts_test , labels_train, labels_test, vocab_length, max_sentence_size = keras_bitcoin.get_train_test_data(texts, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_dico = {\n",
    "  \"number_files_used\": 12,\n",
    "  \"softplus_sigmoid\": 0.7466990947723389,\n",
    "  \"softsign_sigmoid\": 0.7289784550666809,\n",
    "  \"softsign_hard_sigmoid\": 0.7338429689407349,\n",
    "  \"sigmoid_hard_sigmoid\": 0.7515636086463928\n",
    "}\n",
    "epochs=20\n",
    "batch_size=None\n",
    "activations_functions=[\"sigmoid\", \"relu\"]\n",
    "dropouts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "534/534 [==============================] - 0s 494us/step - loss: 0.7808 - acc: 0.4494\n",
      "Epoch 2/20\n",
      "534/534 [==============================] - 0s 148us/step - loss: 0.7320 - acc: 0.4494\n",
      "Epoch 3/20\n",
      "534/534 [==============================] - 0s 145us/step - loss: 0.6930 - acc: 0.4494\n",
      "Epoch 4/20\n",
      "534/534 [==============================] - 0s 127us/step - loss: 0.6603 - acc: 0.5599\n",
      "Epoch 5/20\n",
      "534/534 [==============================] - 0s 133us/step - loss: 0.6272 - acc: 0.8914\n",
      "Epoch 6/20\n",
      "534/534 [==============================] - 0s 129us/step - loss: 0.5946 - acc: 0.9382\n",
      "Epoch 7/20\n",
      "534/534 [==============================] - 0s 124us/step - loss: 0.5589 - acc: 0.9288\n",
      "Epoch 8/20\n",
      "534/534 [==============================] - 0s 120us/step - loss: 0.5193 - acc: 0.9345\n",
      "Epoch 9/20\n",
      "534/534 [==============================] - 0s 116us/step - loss: 0.4738 - acc: 0.9551\n",
      "Epoch 10/20\n",
      "534/534 [==============================] - 0s 110us/step - loss: 0.4254 - acc: 0.9738\n",
      "Epoch 11/20\n",
      "534/534 [==============================] - 0s 120us/step - loss: 0.3762 - acc: 0.9775\n",
      "Epoch 12/20\n",
      "534/534 [==============================] - 0s 140us/step - loss: 0.3281 - acc: 0.9794\n",
      "Epoch 13/20\n",
      "534/534 [==============================] - 0s 122us/step - loss: 0.2838 - acc: 0.9850\n",
      "Epoch 14/20\n",
      "534/534 [==============================] - 0s 125us/step - loss: 0.2441 - acc: 0.9888\n",
      "Epoch 15/20\n",
      "534/534 [==============================] - 0s 114us/step - loss: 0.2092 - acc: 0.9906\n",
      "Epoch 16/20\n",
      "534/534 [==============================] - 0s 112us/step - loss: 0.1785 - acc: 0.9906\n",
      "Epoch 17/20\n",
      "534/534 [==============================] - 0s 99us/step - loss: 0.1518 - acc: 0.9925\n",
      "Epoch 18/20\n",
      "534/534 [==============================] - 0s 114us/step - loss: 0.1283 - acc: 0.9944\n",
      "Epoch 19/20\n",
      "534/534 [==============================] - 0s 107us/step - loss: 0.1091 - acc: 0.9944\n",
      "Epoch 20/20\n",
      "534/534 [==============================] - 0s 103us/step - loss: 0.0951 - acc: 0.9963\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 601       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 84,403\n",
      "Trainable params: 84,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras_bitcoin.get_model(texts_train, labels_train, vocab_length, max_sentence_size, epochs=epochs, batch_size=batch_size, activations_functions=activations_functions, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 463us/step\n",
      "Accuracy: 52.238804\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(texts_test, labels_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded :  668\n",
      "(117152, 3)                                                 text  label        date\n",
      "0                                               body      1  2015-12-15\n",
      "1  Recent comment by him with regards to Gavin An...      1  2015-12-15\n"
     ]
    }
   ],
   "source": [
    "df_test = dataset.get_labeled_dataset(number_of_file = 10, from_date = \"2017-02-10\", date_included = False, all_files=True)\n",
    "print(df_test.shape,df_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = keras_bitcoin.get_predictions(list(df_test[\"text\"]), model, vocab_length, max_sentence_size)\n",
    "df_test[\"preds\"] = list(map(lambda x : int(x), preds))\n",
    "df_test[\"correct\"] = np.equal(preds, df_test[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Correct/Wrong Guess : 18267/98885\n",
      "              Accuracy : 15.592563507238461\n",
      "Invalid sentences count 82195\n"
     ]
    }
   ],
   "source": [
    "dataset.get_prediction_stats(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "elu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "softmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "selu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "softplus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "softsign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "relu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "hard_sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "exponential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 30, 20)            83800     \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 84,401\n",
      "Trainable params: 84,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "{'epochs': 5, 'batch_size': None, 'number_files_used': 12, 'tanh': [0.43283581733703613], 'elu': [0.43283581733703613], 'softmax': [0.5671641826629639], 'selu': [0.43283581733703613], 'softplus': [0.5746268630027771], 'softsign': [0.43283581733703613], 'relu': [0.43283581733703613], 'sigmoid': [0.5746268630027771], 'hard_sigmoid': [0.5447761416435242], 'exponential': [0.5671641826629639], 'linear': [0.43283581733703613]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "epochs=5\n",
    "batch_size=None\n",
    "perfs = {}\n",
    "perfs[\"epochs\"] = epochs\n",
    "perfs[\"batch_size\"] = batch_size\n",
    "perfs[\"number_files_used\"] = 12\n",
    "dropout = {}\n",
    "\n",
    "function_list = get_combinations(keras_bitcoin.available_activation_functions)\n",
    "#function_list = keras_bitcoin.available_activation_functions\n",
    "#function_list = [[\"softplus\", \"relu\", \"exponential\", \"softmax\"]]\n",
    "for function in function_list:\n",
    "    print(function)\n",
    "    \n",
    "    if not isinstance(function, list):\n",
    "        function = [function]\n",
    "    else :\n",
    "        function = list(function)\n",
    "        #dropout[function[0]] = 0.1\n",
    "        #dropout[function[2]] = 0.1\n",
    "    model = keras_bitcoin.get_model(texts_train, labels_train, vocab_length, max_sentence_size, epochs=epochs, batch_size=batch_size, activations_functions=function, verbose = 0)\n",
    "    loss, accuracy = model.evaluate(texts_test, labels_test, verbose=0)\n",
    "    perfs[\"_\".join(function)] = [accuracy]\n",
    "print(perfs)\n",
    "#with open(f\"./keras_stats/ep={epochs}_bats={batch_size}.json\", \"w\") as fp:\n",
    "#    json.dump(perfs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 5,\n",
       " 'batch_size': None,\n",
       " 'number_files_used': 12,\n",
       " 'tanh': [0.43283581733703613],\n",
       " 'elu': [0.43283581733703613],\n",
       " 'softmax': [0.5671641826629639],\n",
       " 'selu': [0.43283581733703613],\n",
       " 'softplus': [0.5746268630027771],\n",
       " 'softsign': [0.43283581733703613],\n",
       " 'relu': [0.43283581733703613],\n",
       " 'sigmoid': [0.5746268630027771],\n",
       " 'hard_sigmoid': [0.5447761416435242],\n",
       " 'exponential': [0.5671641826629639],\n",
       " 'linear': [0.43283581733703613]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        function       min       max       avg\n",
      "0           tanh  0.000000  0.619942  0.382144\n",
      "1            elu  0.000000  0.589487  0.054955\n",
      "2        softmax  0.617438  0.617438  0.449046\n",
      "3           selu  0.000000  0.622862  0.267266\n",
      "4       softplus  0.415102  0.624948  0.409944\n",
      "5       softsign  0.574885  0.617856  0.441006\n",
      "6           relu  0.000000  0.622028  0.161262\n",
      "7        sigmoid  0.600334  0.626617  0.445102\n",
      "8   hard_sigmoid  0.592407  0.619942  0.445102\n",
      "9    exponential  0.000000  0.624531  0.320514\n",
      "10        linear  0.000000  0.618273  0.208367\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"./keras_stats/\"\n",
    "dicts = []\n",
    "for file in os.listdir(directory):\n",
    "    f = open(f'{directory}{file}')\n",
    "    dicts.append(json.load(f))\n",
    "\n",
    "functions = keras_bitcoin.available_activation_functions\n",
    "\n",
    "perfs_stats = {\"function\" : [], \"min\" : [], \"max\" : [], \"avg\" : []}\n",
    "for function in functions:\n",
    "    sum_perfs = 0\n",
    "    min_perfs = 1\n",
    "    max_perfs = -1\n",
    "    for dct in dicts:\n",
    "        value = dct[function]\n",
    "        sum_perfs += value\n",
    "        if value > max_perfs:\n",
    "            max_perfs = value\n",
    "        if value < min_perfs:\n",
    "            min_perfs = value\n",
    "    perfs_stats[\"function\"].append(function)\n",
    "    perfs_stats[\"avg\"].append(sum_perfs / len(functions))\n",
    "    perfs_stats[\"max\"].append(max_perfs)\n",
    "    perfs_stats[\"min\"].append(min_perfs)\n",
    "\n",
    "print(pd.DataFrame(perfs_stats))\n",
    "#softmax softplus softsign sigmoid hard_sigmoid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\"softmax\", \"softplus\", \"softsign\", \"sigmoid\", \"hard_sigmoid\"]\n",
    "def get_combinations(arr):\n",
    "    combinations = []\n",
    "    for i in range(len(arr)):\n",
    "        item = arr[i]\n",
    "        for j in range(i + 1, len(arr)):\n",
    "            combinations.append([item, arr[j]])\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1495, 20)          501200    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 29900)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 29901     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 531,103\n",
      "Trainable params: 531,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "acc :  0.6556636691093445\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "epochs = 5\n",
    "batch_size = None\n",
    "perfs = {}\n",
    "perfs[\"number_files_used\"] = 12\n",
    "functions_list = [[\"sigmoid\",\"hard_sigmoid\"]]\n",
    "dropout_value = 0.2\n",
    "for functions in functions_list:\n",
    "    functions = list(functions)\n",
    "    dropouts = {}\n",
    "    #dropouts[functions[0]] = 0.1\n",
    "    #dropouts[functions[1]] = 0.08\n",
    "    model = keras_bitcoin.get_model(texts_train = texts_train, labels_train = labels_train, vocab_length = vocab_length, max_sentence_size = max_sentence_size, epochs = epochs, \n",
    "    batch_size = batch_size, activations_functions = functions, verbose = 0, dropouts = dropouts)\n",
    "    loss, accuracy = model.evaluate(texts_test, labels_test, verbose=0)\n",
    "    #perfs[\"_\".join(functions)] = accuracy\n",
    "    print(\"acc : \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Correct/Wrong Guess : 2938/448\n",
      "              Accuracy : 86.7690490253987\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 0/2560\n",
      "              Accuracy : 0.0\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 3020/1403\n",
      "              Accuracy : 68.27944833823197\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 1319/880\n",
      "              Accuracy : 59.9818099135971\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 853/1376\n",
      "              Accuracy : 38.26828174069089\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 1038/611\n",
      "              Accuracy : 62.94724075197089\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 693/574\n",
      "              Accuracy : 54.69613259668509\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 1418/332\n",
      "              Accuracy : 81.02857142857142\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 702/1022\n",
      "              Accuracy : 40.71925754060325\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 722/515\n",
      "              Accuracy : 58.36701697655619\n",
      "Invalid sentences count 2\n",
      "Number Correct/Wrong Guess : 194/956\n",
      "              Accuracy : 16.869565217391305\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 718/76\n",
      "              Accuracy : 90.42821158690177\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 3/478\n",
      "              Accuracy : 0.6237006237006237\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 714/228\n",
      "              Accuracy : 75.79617834394905\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 944/139\n",
      "              Accuracy : 87.16528162511543\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 247/346\n",
      "              Accuracy : 41.65261382799326\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 779/341\n",
      "              Accuracy : 69.55357142857143\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 477/153\n",
      "              Accuracy : 75.71428571428571\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 292/153\n",
      "              Accuracy : 65.61797752808988\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 1297/62\n",
      "              Accuracy : 95.43782192788815\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 211/448\n",
      "              Accuracy : 32.01820940819423\n",
      "Invalid sentences count 1\n",
      "Number Correct/Wrong Guess : 61/179\n",
      "              Accuracy : 25.416666666666664\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 274/752\n",
      "              Accuracy : 26.705653021442494\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 183/250\n",
      "              Accuracy : 42.263279445727484\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 892/362\n",
      "              Accuracy : 71.1323763955343\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 295/439\n",
      "              Accuracy : 40.19073569482289\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 396/99\n",
      "              Accuracy : 80.0\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 131/14\n",
      "              Accuracy : 90.3448275862069\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 154/114\n",
      "              Accuracy : 57.46268656716418\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 151/343\n",
      "              Accuracy : 30.5668016194332\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 332/227\n",
      "              Accuracy : 59.391771019677996\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 101/163\n",
      "              Accuracy : 38.25757575757576\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 304/11\n",
      "              Accuracy : 96.5079365079365\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 529/464\n",
      "              Accuracy : 53.272910372608266\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 7/139\n",
      "              Accuracy : 4.794520547945205\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 2/76\n",
      "              Accuracy : 2.564102564102564\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 42/271\n",
      "              Accuracy : 13.418530351437699\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 5/2\n",
      "              Accuracy : 71.42857142857143\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 5/231\n",
      "              Accuracy : 2.11864406779661\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 125/62\n",
      "              Accuracy : 66.84491978609626\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 8/204\n",
      "              Accuracy : 3.7735849056603774\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 10/158\n",
      "              Accuracy : 5.952380952380952\n",
      "Invalid sentences count 2\n",
      "Number Correct/Wrong Guess : 45/5\n",
      "              Accuracy : 90.0\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 313/66\n",
      "              Accuracy : 82.58575197889182\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 3/167\n",
      "              Accuracy : 1.7647058823529411\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 156/10\n",
      "              Accuracy : 93.97590361445783\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 22/46\n",
      "              Accuracy : 32.35294117647059\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 0/472\n",
      "              Accuracy : 0.0\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 106/1\n",
      "              Accuracy : 99.06542056074767\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 200/5\n",
      "              Accuracy : 97.5609756097561\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 2/18\n",
      "              Accuracy : 10.0\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 90/8\n",
      "              Accuracy : 91.83673469387756\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 338/90\n",
      "              Accuracy : 78.97196261682244\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 12/28\n",
      "              Accuracy : 30.0\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 118/2\n",
      "              Accuracy : 98.33333333333333\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 2/16\n",
      "              Accuracy : 11.11111111111111\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 6/158\n",
      "              Accuracy : 3.6585365853658534\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 41/10\n",
      "              Accuracy : 80.3921568627451\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 19/71\n",
      "              Accuracy : 21.11111111111111\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 57/2\n",
      "              Accuracy : 96.61016949152543\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 15/27\n",
      "              Accuracy : 35.714285714285715\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 212/5\n",
      "              Accuracy : 97.6958525345622\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 4/82\n",
      "              Accuracy : 4.651162790697675\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 6/51\n",
      "              Accuracy : 10.526315789473683\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 0/68\n",
      "              Accuracy : 0.0\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 8/98\n",
      "              Accuracy : 7.547169811320755\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 162/3\n",
      "              Accuracy : 98.18181818181819\n",
      "Invalid sentences count 0\n",
      "Number Correct/Wrong Guess : 94/3\n",
      "              Accuracy : 96.90721649484536\n",
      "Invalid sentences count 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-eb2805cffdd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"preds\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"correct\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_prediction_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mlast_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ESILV\\A5\\FeelCrypt\\Valentin\\dataset.py\u001b[0m in \u001b[0;36mget_prediction_stats\u001b[1;34m(df_prediction)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     print(f\"\"\"Number Correct/Wrong Guess : {correct_pred}/{wrong_pred}\n\u001b[1;32m---> 69\u001b[1;33m               Accuracy : {(correct_pred/(correct_pred + wrong_pred)) * 100}\"\"\" )\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid sentences count\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_prediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"preds\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "last_date = \"2010-10-11\"\n",
    "for i in range(200):\n",
    "    df_test = dataset.get_labeled_dataset(number_of_file = 5, from_date = last_date, date_included = False)\n",
    "    preds = keras_bitcoin.get_predictions(list(df_test[\"text\"]), model, vocab_length, max_sentence_size)\n",
    "    df_test[\"preds\"] = list(map(lambda x : int(x), preds))\n",
    "    df_test[\"correct\"] = np.equal(preds, df_test[\"label\"])\n",
    "    #dataset.get_prediction_stats(df_test)\n",
    "    last_date = list(df_test[\"date\"])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " functions = [\"softmax\", \"softplus\", \"softsign\", \"sigmoid\", \"hard_sigmoid\"]\n",
    "    ''' \"softmax_softplus\": 0.6580958962440491,\n",
    "  \"softmax_softsign\": 0.6580958962440491,\n",
    "  \"softmax_sigmoid\": 0.6580958962440491,\n",
    "  \"softmax_hard_sigmoid\": 0.6580958962440491,\n",
    "  \"softplus_softsign\": 0.6580958962440491,\n",
    "  \"softplus_sigmoid\": 0.7466990947723389,\n",
    "  \"softplus_hard_sigmoid\": 0.6580958962440491,\n",
    "  \"softsign_sigmoid\": 0.7289784550666809,\n",
    "  \"softsign_hard_sigmoid\": 0.7338429689407349,\n",
    "  \"sigmoid_hard_sigmoid\": 0.7515636086463928'''\n",
    "    \n",
    "    {\n",
    "  \"softplus_sigmoid\": 0.7466990947723389,\n",
    "  \"softsign_sigmoid\": 0.7289784550666809,\n",
    "  \"softsign_hard_sigmoid\": 0.7338429689407349,\n",
    "  \"sigmoid_hard_sigmoid\": 0.7515636086463928\n",
    "}\n",
    "[[\"softplus\", \"sigmoid\"], [\"softsign\", \"sigmoid\"], [\"softsign\", \"hard_sigmoid\"], [\"sigmoid\", \"hard_sigmoid\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
