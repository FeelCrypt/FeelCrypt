{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras_bitcoin\n",
    "import dataset\n",
    "import collections\n",
    "import pandas as pd\n",
    "from itertools import permutations, combinations\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded :  202\n",
      "Counter({4: 12161, 2: 9441, 1: 7535, 5: 5394, 3: 1868})\n",
      "(36399, 8)\n",
      "                                                text  label        date  \\\n",
      "0          So how does that make it not a currency?       3  2018-01-03   \n",
      "1  I didn't say it wasn't a currency, I'm just sa...      3  2018-01-03   \n",
      "2  I don't think spam has ever been a problem in ...      3  2018-01-03   \n",
      "3  It was electrum wallet bro ._.\\r\\nMy transacti...      3  2018-01-03   \n",
      "4  My laptop has 4 GB Ram, I think it can handle ...      3  2018-01-03   \n",
      "\n",
      "   score  nb_replies  stickied  label_m1  label_m2  \n",
      "0      2           1     False         4         5  \n",
      "1      1           0     False         4         5  \n",
      "2      1           1     False         4         5  \n",
      "3      1           0     False         4         5  \n",
      "4      1           0     False         4         5  \n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"../Data/LDA_Data/reduceData3.csv\")\n",
    "#df = dataset.put_on_label_dataset(df, \"day\", binary=False, values = [-0.5, -0.2, 0.2, 0.5])\n",
    "\n",
    "df = dataset.get_labeled_dataset(number_of_file=200, binary= False, values = [-5, -0.2, 0.2, 5], from_date = \"2018-01-01\")\n",
    "print(collections.Counter(df[\"label\"]))\n",
    "\n",
    "#df = dataset.put_on_label_dataset(df, \"date\")\n",
    "df.head()\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"]\n",
    "texts = keras_bitcoin.encode_data(texts)\n",
    "df = df.drop(columns=[\"text\"])\n",
    "texts = list(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>nb_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>label_m1</th>\n",
       "      <th>label_m2</th>\n",
       "      <th>words_1</th>\n",
       "      <th>words_2</th>\n",
       "      <th>words_3</th>\n",
       "      <th>...</th>\n",
       "      <th>words_222</th>\n",
       "      <th>words_223</th>\n",
       "      <th>words_224</th>\n",
       "      <th>words_225</th>\n",
       "      <th>words_226</th>\n",
       "      <th>words_227</th>\n",
       "      <th>words_228</th>\n",
       "      <th>words_229</th>\n",
       "      <th>words_230</th>\n",
       "      <th>words_231</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20124</td>\n",
       "      <td>24020</td>\n",
       "      <td>24026</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12783</td>\n",
       "      <td>1704</td>\n",
       "      <td>1622</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12783</td>\n",
       "      <td>13027</td>\n",
       "      <td>45692</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>42221</td>\n",
       "      <td>13164</td>\n",
       "      <td>2021</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20576</td>\n",
       "      <td>5796</td>\n",
       "      <td>6113</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        date  score  nb_replies  stickied  label_m1  label_m2  \\\n",
       "0      3  2018-01-03      2           1     False         4         5   \n",
       "1      3  2018-01-03      1           0     False         4         5   \n",
       "2      3  2018-01-03      1           1     False         4         5   \n",
       "3      3  2018-01-03      1           0     False         4         5   \n",
       "4      3  2018-01-03      1           0     False         4         5   \n",
       "\n",
       "   words_1  words_2  words_3  ...  words_222  words_223  words_224  words_225  \\\n",
       "0    20124    24020    24026  ...          0          0          0          0   \n",
       "1    12783     1704     1622  ...          0          0          0          0   \n",
       "2    12783    13027    45692  ...          0          0          0          0   \n",
       "3    42221    13164     2021  ...          0          0          0          0   \n",
       "4    20576     5796     6113  ...          0          0          0          0   \n",
       "\n",
       "   words_226  words_227  words_228  words_229  words_230  words_231  \n",
       "0          0          0          0          0          0          0  \n",
       "1          0          0          0          0          0          0  \n",
       "2          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 238 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3787d8fe4662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"words_{i+1}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentence_length = len(texts[0])\n",
    "for i in range(sentence_length):\n",
    "    words = []\n",
    "    for k in range(len(texts)):\n",
    "        words.append(list(texts)[k][i])\n",
    "    df[f\"words_{i+1}\"] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"]\n",
    "labels = df[\"label\"]\n",
    "texts_train, texts_test , labels_train, labels_test, vocab_length, max_sentence_size\\\n",
    "= keras_bitcoin.get_train_test_data(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-74a8e83e80a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                          \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                          )\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mxg_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxg_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xg_class = XGBClassifier(objective ='reg:tweedie',\n",
    "                         max_depth = 8,\n",
    "                         n_estimators = 100,\n",
    "                         eta = 0.5,\n",
    "                         )\n",
    "xg_class.fit(texts_train,labels_train)\n",
    "preds = xg_class.predict(texts_test)\n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1414835164835164"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xg_class, open(\"xgboost_bitcoin.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33145604395604394\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(\"xgboost_bitcoin.dat\", \"rb\"))\n",
    "\n",
    "preds = loaded_model.predict(texts_test)\n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\"0\" : 0, \"1\" : 0, \"2\" : 0, \"3\" : 0, \"4\" : 0}\n",
    "for i in range(len(labels_test)):\n",
    "    val = abs(list(labels_test)[i] - list(preds)[i])\n",
    "    res[str(val)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0.32362637362637364,\n",
       " '1': 0.20851648351648353,\n",
       " '2': 0.25535714285714284,\n",
       " '3': 0.20302197802197802,\n",
       " '4': 0.009478021978021977}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in res.keys():\n",
    "    res[k] /= len(preds) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9578296703296703"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "\n",
    "mean_squared_error(labels_test, [random.randint(1, 5) for x in labels_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "batch_size=None\n",
    "perfs = {}\n",
    "dropouts = []\n",
    "\n",
    "\n",
    "#reducedata2\n",
    "#function_list = ['tanh', 'softmax', 'softsign', 'hard_sigmoid']\n",
    "#function_list =  list(combinations(function_list, 3))\n",
    "#function_list = ['softmax', 'softplus', 'sigmoid', 'hard_sigmoid', 'exponential']\n",
    "#function_list =  list(combinations(function_list, 2))\n",
    "\n",
    "\n",
    "\n",
    "#stem only\n",
    "function_list = [['softsign', 'relu', 'sigmoid', \"tanh\"]]\n",
    "#no dropout\n",
    "#function_list = [['tanh', 'softmax'], ['tanh', 'softplus'], ['tanh', 'sigmoid'], ['tanh', 'hard_sigmoid'], ['tanh', 'exponential'], ['softmax', 'sigmoid'], ['softmax', 'hard_sigmoid'], 'softmax', 'exponential'], ['softplus', 'softsign'], ['softplus', 'sigmoid'], ['softplus', 'hard_sigmoid'], ['softplus', 'exponential'], ['softsign', 'sigmoid'], ['softsign', 'hard_sigmoid'], ['softsign', 'exponential'], ['sigmoid', 'hard_sigmoid'], ['hard_sigmoid', 'exponential']]\n",
    "#function_list =  list(combinations(function_list, 2))\n",
    "temp = []\n",
    "\n",
    "\n",
    "#function_list =  list(combinations([\"softmax\", \"softplus\", \"softsign\", \"sigmoid\", \"hard_sigmoid\"], ))\n",
    "#scrambled_list = [ 'tanh', 'softmax' ,'softplus', 'sigmoid', 'hard_sigmoid', 'exponential','linear']\n",
    "#random.shuffle(scrambled_list)\n",
    "#function_list =  list(combinations(scrambled_list, 3))\n",
    "#function_list =  list(combinations(keras_bitcoin.available_activation_functions, 3))\n",
    "\n",
    "size = len(function_list)\n",
    "count = 0\n",
    "for function in function_list:\n",
    "    count += 1\n",
    "    print(count, size)\n",
    "    if isinstance(function, str):\n",
    "        function = [function]\n",
    "    else :\n",
    "        function = list(function)\n",
    "        dropouts = [0.1, 0.1]\n",
    "    model = keras_bitcoin.get_model(texts_train, labels_train, vocab_length,\\\n",
    "                                    max_sentence_size, epochs=epochs,\\\n",
    "                                    batch_size=batch_size, activations_functions=function,\\\n",
    "                                    dropouts=dropouts, verbose = 0)\n",
    "    loss, accuracy = model.evaluate(texts_test, labels_test, verbose=0)\n",
    "    preds = model.predict(texts_test)\n",
    "    if accuracy >= 0.5:\n",
    "        temp.append(function)\n",
    "    perfs[\"_\".join(function)] = [accuracy, mean_squared_error(labels_test, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'softsign_relu_sigmoid_tanh': [0.0, 15.333236874968053]}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded :  10\n"
     ]
    }
   ],
   "source": [
    "df_test = dataset.get_labeled_dataset(number_of_file = 10, from_date = \"2017-02-10\", date_included = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = keras_bitcoin.get_predictions(list(df_test[\"text\"]), model, vocab_length, max_sentence_size)\n",
    "df_test[\"preds\"] = list(map(lambda x : int(x), preds))\n",
    "df_test[\"correct\"] = np.equal(preds, df_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Correct/Wrong Guess : 5/363\n",
      "              Accuracy : 1.358695652173913\n",
      "Invalid sentences count 0\n"
     ]
    }
   ],
   "source": [
    "dataset.get_prediction_stats(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambled_list = list(random.shuffle([ 'tanh', 'softmax' ,'softplus', 'sigmoid', 'hard_sigmoid', 'exponential','linear']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
