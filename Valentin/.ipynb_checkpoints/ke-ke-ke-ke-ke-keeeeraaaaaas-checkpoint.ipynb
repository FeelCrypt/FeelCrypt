{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_bitcoin\n",
    "import dataset\n",
    "import collections\n",
    "import pandas as pd\n",
    "from itertools import permutations, combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "import moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded :  102\n",
      "Counter({4: 8112, 1: 6883, 2: 6798, 5: 4564, 3: 1685})\n",
      "(28042, 8)\n",
      "                                                text  label        date  \\\n",
      "0          So how does that make it not a currency?       3  2018-01-03   \n",
      "1  I didn't say it wasn't a currency, I'm just sa...      3  2018-01-03   \n",
      "2  I don't think spam has ever been a problem in ...      3  2018-01-03   \n",
      "3  It was electrum wallet bro ._.\\r\\nMy transacti...      3  2018-01-03   \n",
      "4  My laptop has 4 GB Ram, I think it can handle ...      3  2018-01-03   \n",
      "\n",
      "   score  nb_replies  stickied  label_m1  label_m2  \n",
      "0      2           1     False         4         5  \n",
      "1      1           0     False         4         5  \n",
      "2      1           1     False         4         5  \n",
      "3      1           0     False         4         5  \n",
      "4      1           0     False         4         5  \n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"../Data/LDA_Data/reduceData3.csv\")\n",
    "#df = dataset.put_on_label_dataset(df, \"day\", binary=False, values = [-0.5, -0.2, 0.2, 0.5])\n",
    "\n",
    "df = dataset.get_labeled_dataset(number_of_file=100, binary= False, values = [-5, -0.2, 0.2, 5], from_date = \"2018-01-01\")\n",
    "print(collections.Counter(df[\"label\"]))\n",
    "\n",
    "#df = dataset.put_on_label_dataset(df, \"date\")\n",
    "df.head()\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"]\n",
    "texts = keras_bitcoin.encode_data(texts)\n",
    "df = df.drop(columns=[\"text\"])\n",
    "texts = list(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_length = len(texts[0])\n",
    "for i in range(sentence_length):\n",
    "    words = [texts[k][i] for k in range(len(texts))]\n",
    "    df[f\"word_{i+1}\"] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = [int(str(date)[0:4]) for date in df[\"date\"]]\n",
    "df[\"month\"] = [int(str(date)[5:7]) for date in df[\"date\"]]\n",
    "df[\"day\"] = [int(str(date)[8:10]) for date in df[\"date\"]]\n",
    "df = df.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_test , labels_train, labels_test = train_test_split(df.drop(columns=[\"label\"]), df[\"label\"] , test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>nb_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>label_m1</th>\n",
       "      <th>label_m2</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>...</th>\n",
       "      <th>word_1938</th>\n",
       "      <th>word_1939</th>\n",
       "      <th>word_1940</th>\n",
       "      <th>word_1941</th>\n",
       "      <th>word_1942</th>\n",
       "      <th>word_1943</th>\n",
       "      <th>word_1944</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7680</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10389</td>\n",
       "      <td>3842</td>\n",
       "      <td>5854</td>\n",
       "      <td>31243</td>\n",
       "      <td>15852</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11905</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28314</td>\n",
       "      <td>26299</td>\n",
       "      <td>12828</td>\n",
       "      <td>39431</td>\n",
       "      <td>26565</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9804</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>28314</td>\n",
       "      <td>32096</td>\n",
       "      <td>38659</td>\n",
       "      <td>39416</td>\n",
       "      <td>38013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7826</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>33323</td>\n",
       "      <td>14419</td>\n",
       "      <td>17084</td>\n",
       "      <td>11430</td>\n",
       "      <td>4802</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>37731</td>\n",
       "      <td>3255</td>\n",
       "      <td>23495</td>\n",
       "      <td>10055</td>\n",
       "      <td>20657</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1952 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  nb_replies  stickied  label_m1  label_m2  word_1  word_2  \\\n",
       "7680      25           0     False         2         4   10389    3842   \n",
       "11905      1           0     False         4         1   28314   26299   \n",
       "9804       4           0     False         3         2   28314   32096   \n",
       "7826       7           0     False         2         4   33323   14419   \n",
       "16924      1           1     False         5         2   37731    3255   \n",
       "\n",
       "       word_3  word_4  word_5  ...  word_1938  word_1939  word_1940  \\\n",
       "7680     5854   31243   15852  ...          0          0          0   \n",
       "11905   12828   39431   26565  ...          0          0          0   \n",
       "9804    38659   39416   38013  ...          0          0          0   \n",
       "7826    17084   11430    4802  ...          0          0          0   \n",
       "16924   23495   10055   20657  ...          0          0          0   \n",
       "\n",
       "       word_1941  word_1942  word_1943  word_1944  year  month  day  \n",
       "7680           0          0          0          0  2018      1   14  \n",
       "11905          0          0          0          0  2018      1   23  \n",
       "9804           0          0          0          0  2018      1   18  \n",
       "7826           0          0          0          0  2018      1   14  \n",
       "16924          0          0          0          0  2018      2    8  \n",
       "\n",
       "[5 rows x 1952 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"]\n",
    "labels = df[\"label\"]\n",
    "texts_train, texts_test , labels_train, labels_test, vocab_length, max_sentence_size\\\n",
    "= keras_bitcoin.get_train_test_data(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xg_class = XGBClassifier(objective ='reg:tweedie',\n",
    "                         max_depth = 8,\n",
    "                         n_estimators = 100,\n",
    "                         eta = 0.5,\n",
    "                         )\n",
    "xg_class.fit(texts_train,labels_train)\n",
    "preds = xg_class.predict(texts_test)\n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xg_class, open(\"xgboost_bitcoin.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33145604395604394\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(\"xgboost_bitcoin.dat\", \"rb\"))\n",
    "\n",
    "preds = loaded_model.predict(texts_test)\n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\"0\" : 0, \"1\" : 0, \"2\" : 0, \"3\" : 0, \"4\" : 0}\n",
    "for i in range(len(labels_test)):\n",
    "    val = abs(list(labels_test)[i] - list(preds)[i])\n",
    "    res[str(val)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0.32362637362637364,\n",
       " '1': 0.20851648351648353,\n",
       " '2': 0.25535714285714284,\n",
       " '3': 0.20302197802197802,\n",
       " '4': 0.009478021978021977}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in res.keys():\n",
    "    res[k] /= len(preds) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9578296703296703"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "\n",
    "mean_squared_error(labels_test, [random.randint(1, 5) for x in labels_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "batch_size=None\n",
    "perfs = {}\n",
    "dropouts = []\n",
    "\n",
    "\n",
    "#reducedata2\n",
    "#function_list = ['tanh', 'softmax', 'softsign', 'hard_sigmoid']\n",
    "#function_list =  list(combinations(function_list, 3))\n",
    "#function_list = ['softmax', 'softplus', 'sigmoid', 'hard_sigmoid', 'exponential']\n",
    "#function_list =  list(combinations(function_list, 2))\n",
    "\n",
    "\n",
    "\n",
    "#stem only\n",
    "function_list = [['softsign', 'relu', 'sigmoid', \"tanh\"]]\n",
    "#no dropout\n",
    "#function_list = [['tanh', 'softmax'], ['tanh', 'softplus'], ['tanh', 'sigmoid'], ['tanh', 'hard_sigmoid'], ['tanh', 'exponential'], ['softmax', 'sigmoid'], ['softmax', 'hard_sigmoid'], 'softmax', 'exponential'], ['softplus', 'softsign'], ['softplus', 'sigmoid'], ['softplus', 'hard_sigmoid'], ['softplus', 'exponential'], ['softsign', 'sigmoid'], ['softsign', 'hard_sigmoid'], ['softsign', 'exponential'], ['sigmoid', 'hard_sigmoid'], ['hard_sigmoid', 'exponential']]\n",
    "#function_list =  list(combinations(function_list, 2))\n",
    "temp = []\n",
    "\n",
    "\n",
    "#function_list =  list(combinations([\"softmax\", \"softplus\", \"softsign\", \"sigmoid\", \"hard_sigmoid\"], ))\n",
    "#scrambled_list = [ 'tanh', 'softmax' ,'softplus', 'sigmoid', 'hard_sigmoid', 'exponential','linear']\n",
    "#random.shuffle(scrambled_list)\n",
    "#function_list =  list(combinations(scrambled_list, 3))\n",
    "#function_list =  list(combinations(keras_bitcoin.available_activation_functions, 3))\n",
    "\n",
    "size = len(function_list)\n",
    "count = 0\n",
    "for function in function_list:\n",
    "    count += 1\n",
    "    print(count, size)\n",
    "    if isinstance(function, str):\n",
    "        function = [function]\n",
    "    else :\n",
    "        function = list(function)\n",
    "        dropouts = [0.1, 0.1]\n",
    "    model = keras_bitcoin.get_model(texts_train, labels_train, vocab_length,\\\n",
    "                                    max_sentence_size, epochs=epochs,\\\n",
    "                                    batch_size=batch_size, activations_functions=function,\\\n",
    "                                    dropouts=dropouts, verbose = 0)\n",
    "    loss, accuracy = model.evaluate(texts_test, labels_test, verbose=0)\n",
    "    preds = model.predict(texts_test)\n",
    "    if accuracy >= 0.5:\n",
    "        temp.append(function)\n",
    "    perfs[\"_\".join(function)] = [accuracy, mean_squared_error(labels_test, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'softsign_relu_sigmoid_tanh': [0.0, 15.333236874968053]}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded :  10\n"
     ]
    }
   ],
   "source": [
    "df_test = dataset.get_labeled_dataset(number_of_file = 10, from_date = \"2017-02-10\", date_included = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = keras_bitcoin.get_predictions(list(df_test[\"text\"]), model, vocab_length, max_sentence_size)\n",
    "df_test[\"preds\"] = list(map(lambda x : int(x), preds))\n",
    "df_test[\"correct\"] = np.equal(preds, df_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Correct/Wrong Guess : 5/363\n",
      "              Accuracy : 1.358695652173913\n",
      "Invalid sentences count 0\n"
     ]
    }
   ],
   "source": [
    "dataset.get_prediction_stats(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambled_list = list(random.shuffle([ 'tanh', 'softmax' ,'softplus', 'sigmoid', 'hard_sigmoid', 'exponential','linear']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
