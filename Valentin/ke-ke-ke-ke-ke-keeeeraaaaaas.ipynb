{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras_bitcoin\n",
    "import dataset\n",
    "import collections\n",
    "import pandas as pd\n",
    "from itertools import permutations, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded :  100\n",
      "Counter({1: 2269, 0: 1111})\n",
      "                                                text  label        date  \\\n",
      "0  Recent comment by him with regards to Gavin An...      1  2015-12-15   \n",
      "1          I'm glad your trolling has come to an end      1  2015-12-15   \n",
      "2                              r/bitcoinall is great      1  2015-12-15   \n",
      "3                                  /r/bitcoinxt ftw!      1  2015-12-15   \n",
      "4  > their passion is financially incentivised.\\r...      1  2015-12-15   \n",
      "\n",
      "   score  nb_replies  stickied  \n",
      "0     97           3     False  \n",
      "1    -46           1     False  \n",
      "2      7           0     False  \n",
      "3     20           1     False  \n",
      "4      9           0     False  \n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"../Data/LDA_Data/save3.csv\")\n",
    "df = dataset.get_labeled_dataset(number_of_file=100)\n",
    "print(collections.Counter(df[\"label\"]))\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "textColumnName = \"text\"\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w.lower() not in stopwords.words(\"english\")]\n",
    "    return words\n",
    "\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c.lower() for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "def stem_sentence(sentence_array):\n",
    "    return list(map(lambda word: porter.stem(word),sentence_array))\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "#df[textColumnName] = [remove_punctuation(x) for x in df[textColumnName]]\n",
    "df[textColumnName] = [tknzr.tokenize(x) for x in df[textColumnName]]\n",
    "#df[textColumnName] = [remove_stopwords(x) for x in df[textColumnName]]\n",
    "df[textColumnName] = [stem_sentence(x) for x in df[textColumnName]]\n",
    "df[textColumnName] = [\" \".join(x) for x in df[textColumnName]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(862, 6)\n",
      "                                                text  label        date  \\\n",
      "0  recent comment regard gavin andresen cours los...      1  2015-12-15   \n",
      "1                             im glad troll come end      1  2015-12-15   \n",
      "2                                   rbitcoinal great      1  2015-12-15   \n",
      "3                                     rbitcoinxt ftw      1  2015-12-15   \n",
      "4   passion financi incentivis transpar way unfortun      1  2015-12-15   \n",
      "\n",
      "   score  nb_replies  stickied  \n",
      "0     97           3     False  \n",
      "1    -46           1     False  \n",
      "2      7           0     False  \n",
      "3     20           1     False  \n",
      "4      9           0     False  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[textColumnName]\n",
    "labels = df[\"label\"]\n",
    "texts_train, texts_test , labels_train, labels_test, vocab_length, max_sentence_size\\\n",
    "= keras_bitcoin.get_train_test_data(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33777\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "epochs=8\n",
    "batch_size=None\n",
    "perfs = {}\n",
    "dropouts = []\n",
    "\n",
    "\n",
    "\n",
    "#function_list = keras_bitcoin.available_activation_functions\n",
    "#stem only\n",
    "function_list = ['tanh',\n",
    " 'softmax',\n",
    " 'softplus',\n",
    " 'softsign',\n",
    " 'sigmoid',\n",
    " 'hard_sigmoid',\n",
    " 'exponential'\n",
    " ]\n",
    "#no dropout\n",
    "function_list = [['tanh', 'softmax'],\n",
    " ['tanh', 'softplus'],\n",
    " ['tanh', 'sigmoid'],\n",
    " ['tanh', 'hard_sigmoid'],\n",
    " ['tanh', 'exponential'],\n",
    " ['softmax', 'sigmoid'],\n",
    " ['softmax', 'hard_sigmoid'],\n",
    " ['softmax', 'exponential'],\n",
    " ['softplus', 'softsign'],\n",
    " ['softplus', 'sigmoid'],\n",
    " ['softplus', 'hard_sigmoid'],\n",
    " ['softplus', 'exponential'],\n",
    " ['softsign', 'sigmoid'],\n",
    " ['softsign', 'hard_sigmoid'],\n",
    " ['softsign', 'exponential'],\n",
    " ['sigmoid', 'hard_sigmoid'],\n",
    " ['hard_sigmoid', 'exponential']]\n",
    "#function_list =  list(combinations(function_list, 2))\n",
    "temp = []\n",
    "\n",
    "\n",
    "#function_list =  list(combinations([\"softmax\", \"softplus\", \"softsign\", \"sigmoid\", \"hard_sigmoid\"], ))\n",
    "#scrambled_list = [ 'tanh', 'softmax' ,'softplus', 'sigmoid', 'hard_sigmoid', 'exponential','linear']\n",
    "#random.shuffle(scrambled_list)\n",
    "#function_list =  list(combinations(scrambled_list, 3))\n",
    "#function_list =  list(combinations(keras_bitcoin.available_activation_functions, 2))\n",
    "\n",
    "size = len(function_list)\n",
    "count = 0\n",
    "for function in function_list:\n",
    "    count += 1\n",
    "    print(count, size)\n",
    "    if isinstance(function, str):\n",
    "        function = [function]\n",
    "    else :\n",
    "        function = list(function)\n",
    "        dropouts = [0.3, 0.1]\n",
    "    model = keras_bitcoin.get_model(texts_train, labels_train, vocab_length,\\\n",
    "                                    max_sentence_size, epochs=epochs,\\\n",
    "                                    batch_size=batch_size, activations_functions=function,\\\n",
    "                                    dropouts=dropouts, verbose = 0)\n",
    "    loss, accuracy = model.evaluate(texts_test, labels_test, verbose=0)\n",
    "    if accuracy > 0.55:\n",
    "        temp.append(function)\n",
    "    perfs[\"_\".join(function)] = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tanh', 'softmax'],\n",
       " ['tanh', 'softplus'],\n",
       " ['tanh', 'sigmoid'],\n",
       " ['tanh', 'hard_sigmoid'],\n",
       " ['tanh', 'exponential'],\n",
       " ['softmax', 'sigmoid'],\n",
       " ['softmax', 'hard_sigmoid'],\n",
       " ['softmax', 'exponential'],\n",
       " ['softplus', 'softsign'],\n",
       " ['softplus', 'sigmoid'],\n",
       " ['softplus', 'hard_sigmoid'],\n",
       " ['softplus', 'exponential'],\n",
       " ['softsign', 'sigmoid'],\n",
       " ['softsign', 'hard_sigmoid'],\n",
       " ['softsign', 'exponential'],\n",
       " ['sigmoid', 'hard_sigmoid'],\n",
       " ['hard_sigmoid', 'exponential']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files loaded :  10\n"
     ]
    }
   ],
   "source": [
    "df_test = dataset.get_labeled_dataset(number_of_file = 10, from_date = \"2017-02-10\", date_included = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = keras_bitcoin.get_predictions(list(df_test[\"text\"]), model, vocab_length, max_sentence_size)\n",
    "df_test[\"preds\"] = list(map(lambda x : int(x), preds))\n",
    "df_test[\"correct\"] = np.equal(preds, df_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Correct/Wrong Guess : 5/363\n",
      "              Accuracy : 1.358695652173913\n",
      "Invalid sentences count 0\n"
     ]
    }
   ],
   "source": [
    "dataset.get_prediction_stats(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambled_list = list(random.shuffle([ 'tanh', 'softmax' ,'softplus', 'sigmoid', 'hard_sigmoid', 'exponential','linear']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
