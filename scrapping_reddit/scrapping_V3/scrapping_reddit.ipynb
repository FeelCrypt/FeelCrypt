{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1) Configuration de PRAW (Python Reddit Api Wrapper)\n",
    "## !! A faire avant de pouvoir utiliser n'importe laquelle des parties suivantes !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw               # API pour reddit\n",
    "import pandas as pd       # pour afficher les dictionnaires sous forme de tableaux\n",
    "import datetime as dt     # Pour convertir la date au bon format\n",
    "import os\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer la variable de configuration pour accéder aux requêtes vers reddit\n",
    "reddit = praw.Reddit(client_id='BEjar6X3GYV5Vw', \\\n",
    "                     client_secret='lg6D6DXG14FH4kHtGVt7cins5OY', \\\n",
    "                     user_agent='feelcrypt', \\\n",
    "                     username='feelcrypt', \\\n",
    "                     password='spiderminute38')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Générer la liste des posts à traiter\n",
    "## !! Ne lancer qu'une fois par subreddit !!\n",
    "\n",
    "Cette partie va récupérer les 500 top posts du subreddit défini et sauvegarder uniquement les id de ces posts dans une liste de post à traiter (un fichier txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de configuration globale\n",
    "nb_top_posts = 5  # nombre de posts selectionnés parmi les premiers (limite = 500)\n",
    "subreddit_title = 'btc' # Définir le titre du subreddit que l'on va cibler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer le chemin en fonction du subreddit traité\n",
    "def create_subreddit_folder(subreddit_title):\n",
    "    script_dir_path = %pwd\n",
    "    subreddit_path = script_dir_path + '\\\\'+ subreddit_title +'\\\\' #\n",
    "    try:\n",
    "        os.makedirs(subreddit_path)\n",
    "        print('Dossier créé : ' + subreddit_title) # Log\n",
    "    except FileExistsError:\n",
    "        print('Dossier déjà existant : ' + subreddit_title) # Log\n",
    "        pass\n",
    "    return subreddit_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si le dossier comments (chemin relatif) existe, sinon le créer\n",
    "def create_comments_folder(subreddit_path):\n",
    "    folder_name = 'comments'\n",
    "    comments_path = subreddit_path + folder_name\n",
    "    try:\n",
    "        os.makedirs(comments_path)\n",
    "        print('Dossier créé : ' + folder_name) # Log\n",
    "    except FileExistsError:\n",
    "        print('Dossier déjà existant : ' + folder_name) # Log\n",
    "        pass\n",
    "    return comments_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer la liste des id des posts à traiter\n",
    "def create_id_todo(subreddit_path):\n",
    "    # Créer la variable sur le subreddit\n",
    "    subreddit = reddit.subreddit(subreddit_title)\n",
    "    \n",
    "    # Récupérer les n premiers posts de notre subreddit de notre liste\n",
    "    top_posts = []\n",
    "\n",
    "    for post in subreddit.top(limit = nb_top_posts):\n",
    "        top_posts.append(post)\n",
    "\n",
    "    # Enregistrer les id dans une liste\n",
    "    top_posts_id = []\n",
    "    for post in top_posts:\n",
    "        top_posts_id.append(post.id)\n",
    "\n",
    "    # Enregistrer la liste des id dans un fichier txt\n",
    "\n",
    "    # Créer le chemin de la liste d'id à traiter\n",
    "    file_name = 'id_todo.txt'\n",
    "    id_todo__path = subreddit_path + file_name\n",
    "\n",
    "    # Remplir la liste avec les id\n",
    "    top_posts_id_file = open(id_todo__path,'w')\n",
    "    for post_id in top_posts_id:\n",
    "         top_posts_id_file.write(post_id)\n",
    "         top_posts_id_file.write('\\n')\n",
    "    top_posts_id_file.close()\n",
    "    \n",
    "    # Log\n",
    "    print('Fichier initialisé : ' + file_name)\n",
    "    \n",
    "    return id_todo__path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le fichier pour compter le nombre de commentaires total\n",
    "# Le créer et le réinitialiser à 0 s'il existe déjà\n",
    "def create_counter(subreddit_path):\n",
    "    file_name = 'comments_counter.txt'\n",
    "    counter__path = subreddit_path + file_name\n",
    "    nb_file = open(counter__path,'w').close()\n",
    "    nb_file = open(counter__path,'w')\n",
    "    nb_file.write(str(0))\n",
    "    nb_file.close()\n",
    "    \n",
    "    # log\n",
    "    print('Fichier initialisé : ' + file_name)\n",
    "    \n",
    "    return counter__path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier créé : btc\n",
      "Dossier créé : comments\n",
      "Fichier initialisé : id_todo.txt\n",
      "Fichier initialisé : comments_counter.txt\n"
     ]
    }
   ],
   "source": [
    "# Créer un dossier pour le subreddit\n",
    "subreddit_path = create_subreddit_folder(subreddit_title)\n",
    "\n",
    "# Vérifier si le dossier comments (chemin relatif) existe, sinon le créer\n",
    "comments_path = create_comments_folder(subreddit_path)\n",
    "\n",
    "# Créer la liste des id des posts à traiter\n",
    "id_todo_path = create_id_todo(subreddit_path)\n",
    "\n",
    "# Créer le fichier pour compter le nombre de commentaires total\n",
    "counter_path = create_counter(subreddit_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Traiter les posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales\n",
    "\n",
    "scrap_all_comments = False\n",
    "# Si false : prend seulement les 32 premiers commentaires de chaque post\n",
    "# Si true : prend tous les commentaires du post\n",
    "\n",
    "scrap_responses_to_comments = False\n",
    "# Si false : ne prend que les réponses directes au post\n",
    "# Si true : prend également en compte les réponses aux commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de conversion pour la date avec timestamp\n",
    "def get_date(created):\n",
    "    return dt.date.fromtimestamp(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter le nb de commentaires traités dans le compteur\n",
    "def updating_counter(counter_path, nb_comments, current_post_id):\n",
    "        nb_file = open(counter_path,'r')\n",
    "        total_comments = int(nb_file.read())\n",
    "        total_comments += nb_comments\n",
    "        nb_file.close()\n",
    "        nb_file = open(counter_path,'w').close()\n",
    "        nb_file = open(counter_path,'w')\n",
    "        nb_file.write(str(total_comments))\n",
    "        nb_file.close()\n",
    "        \n",
    "        print(str(nb_comments) + \" comments from post \" + str(current_post_id))\n",
    "        print('total comments saved = ' + str(total_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter chaque id du fichier todo\n",
    "def get_comments(id_todo):\n",
    "    while id_todo:  # Vérifier si la liste n'est pas vide\n",
    "\n",
    "        # Récupérer le post\n",
    "        post = reddit.submission(id = id_todo[0])\n",
    "        current_post_id = post.id\n",
    "        print('-----------------------------------')\n",
    "        print('Starting working on post : ' + str(current_post_id))\n",
    "\n",
    "        ## Récupérer les commentaires du poste\n",
    "        \n",
    "        #Réinitialiser le dictionnaire\n",
    "        comments_dict = { \"created_utc\":[], \\\n",
    "                         \"body\":[], \\\n",
    "                         \"score\":[], \\\n",
    "                         \"nb_replies\":[], \\\n",
    "                         \"stickied\":[], \\\n",
    "                         \"author\":[], \\\n",
    "                         \"id\":[]} \n",
    "\n",
    "        #se débarasser récursivement de la limite de 32 commentaires par requête\n",
    "        if scrap_all_comments:\n",
    "            post.comments.replace_more(limit=None)  # prendre en compte les commentaires supp\n",
    "        else:\n",
    "            post.comments.replace_more(limit=0)    # ignorer les commentaires supp\n",
    "\n",
    "        # Récupérer la liste des commentaires\n",
    "        if scrap_responses_to_comments:\n",
    "            comments_list = post.comments.list()\n",
    "        else:\n",
    "            comments_list = post.comments\n",
    "\n",
    "        # Remplir le dictionnaire de commentaires avec la liste  \n",
    "        for comment in comments_list:\n",
    "            comments_dict[\"created_utc\"].append(comment.created_utc)\n",
    "            comments_dict[\"body\"].append(comment.body)\n",
    "            comments_dict[\"score\"].append(comment.score)\n",
    "            comments_dict[\"nb_replies\"].append(len(comment.replies))\n",
    "            comments_dict[\"stickied\"].append(comment.stickied)\n",
    "            comments_dict[\"author\"].append(comment.author)\n",
    "            comments_dict[\"id\"].append(comment.id)\n",
    "\n",
    "        # mettre la data au format pandas (qui permet de faire un \"tableur\" à partir du dictionnaire)\n",
    "        comments_data = pd.DataFrame(comments_dict)\n",
    "\n",
    "        # Créer la liste des dates converties et la sauvgarder dans la variable _timstamp\n",
    "        # created_utc est la colonne contenant les dates au mauvais format\n",
    "        _timestamp = comments_data[\"created_utc\"].apply(get_date)\n",
    "\n",
    "        # ajouter la liste à une nouvelle colonne appelée timestamp\n",
    "        comments_data = comments_data.assign(date = _timestamp)\n",
    "\n",
    "        # Supprimer la colonne du temps inutile\n",
    "        comments_data = comments_data.drop(columns=\"created_utc\")\n",
    "\n",
    "        # Déplacer la date en première position\n",
    "        colonnes = comments_data.columns.tolist()\n",
    "        colonnes = colonnes[-1:] + colonnes[:-1]\n",
    "        comments_data = comments_data[colonnes]\n",
    "\n",
    "        # Trier par la colonne date\n",
    "        comments_sorted = comments_data.sort_values(by=['date'])\n",
    "\n",
    "        ## Extraire plusieurs dataframe qui représentent chacun une date avec tous les commentaires dedans\n",
    "        # Récupérer la liste des dates et indexer par dates\n",
    "        comments_sorted.set_index(keys=['date'], drop=False,inplace=True)\n",
    "        dates = comments_sorted['date'].unique().tolist()\n",
    "\n",
    "        # Enregistrer dans une liste contenant chaque dataframe (1 data frame = 1 date)\n",
    "        comments_splitperday = []\n",
    "        for date in dates:\n",
    "            comments_per_day = pd.DataFrame(comments_sorted.loc[comments_sorted.date == date])\n",
    "            comments_splitperday.append(comments_per_day)\n",
    "\n",
    "        # Enregistrer chaque dataframe dans un fichier csv\n",
    "        for dataframe in comments_splitperday:\n",
    "            # Récupérer la date du dataframe supprimer la colonne date\n",
    "            date = str(dataframe.date.iloc[0])\n",
    "            dataframe = dataframe.drop(columns=\"date\")\n",
    "            csv_path = comments_path + \"\\\\\" + date + '.csv'\n",
    "\n",
    "            # Enregistrer au format csv avec pour nom la date\n",
    "            dataframe.to_csv(csv_path, ';', mode='a', index=False, header=True) \n",
    "\n",
    "        # Retirer le premier id de la liste, le laisser à la fin, si le while est interrompu, il sera retiré alors que le post n'aura pas été traité\n",
    "        id_todo.pop(0)\n",
    "\n",
    "        # Ajouter l'id du post lu dans la liste des id_done\n",
    "        id_done_path = subreddit_path + \"id_done.txt\"\n",
    "        with open(id_done_path, \"a\") as file:\n",
    "            file.write(current_post_id)\n",
    "\n",
    "        # Enregistrer la nouvelle liste des id_todo dans le fichier txt (ou le créer s'il n'existe pas encore)\n",
    "        with open(id_todo_path, \"r\") as file:\n",
    "            data = file.read()\n",
    "        with open(id_todo_path, \"w\") as file:\n",
    "            for post_id in id_todo:\n",
    "                file.write(post_id)\n",
    "\n",
    "        # Ajouter le nb de commentaires traités dans le compteur\n",
    "        updating_counter(counter_path, len(comments_data.index), current_post_id)\n",
    "        \n",
    "    else:\n",
    "        print('============================================')\n",
    "        print(\"La liste est vide, tout a été traité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouvrir la liste de posts pas encore faits\n",
    "with open(id_todo_path) as file:\n",
    "  id_todo = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Starting working on post : 7eil12\n",
      "\n",
      "167 comments from post 7eil12\n",
      "\n",
      "total comments saved = 167\n",
      "-----------------------------------\n",
      "Starting working on post : 7opi7w\n",
      "\n",
      "119 comments from post 7opi7w\n",
      "\n",
      "total comments saved = 286\n",
      "-----------------------------------\n",
      "Starting working on post : 7hzklb\n",
      "\n",
      "95 comments from post 7hzklb\n",
      "\n",
      "total comments saved = 381\n",
      "-----------------------------------\n",
      "Starting working on post : 7kxfor\n",
      "\n",
      "199 comments from post 7kxfor\n",
      "\n",
      "total comments saved = 580\n",
      "-----------------------------------\n",
      "Starting working on post : 7dzqhm\n",
      "\n",
      "71 comments from post 7dzqhm\n",
      "\n",
      "total comments saved = 651\n",
      "============================================\n",
      "La liste est vide, tout a été traité\n"
     ]
    }
   ],
   "source": [
    "# Traiter chaque id du fichier todo\n",
    "get_comments(id_todo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Supprimer toute la data\n",
    "utile uniquement en debbug, permet de supprimer tous les dossiers générés et leur contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Delete_all_data():\n",
    "    if os.path.isdir(subreddit_path):\n",
    "        shutil.rmtree(subreddit_path)\n",
    "        print('Dossier supprimé : ' + subreddit_path)\n",
    "    else:\n",
    "        print('Dossier inexistant : ' + subreddit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
